{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Image Data\n",
    "\n",
    "[구글 Colab에서 실행하기](https://colab.research.google.com/github/aonekoda/DL-PyTorch/blob/master/02CNN/01ImagePreprocess_ex.ipynb)\n",
    "\n",
    "강아지와 고양이를 구분하는 이미지 분류기를 생성하기 위해서는 고양이와 강아지 사진을 모아야 한다. 임의로 수집된 다음과 같은 고양이/강아지 사진을 사용하자.\n",
    "![img](../assets/dog_cat.png)\n",
    "이 사진을 사용하여 CNN으로 이미지 분류기를 만들기 위해서는 해당 사진을 적절히 전처리하여야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 전처리하기 위해 가장 쉽고 편한 방법은 `torchvision`패키지의 `datasets.ImageFolder` 을 사용하는 것이다.  ([documentation](http://pytorch.org/docs/master/torchvision/datasets.html#imagefolder)). 일반적으로  `ImageFolder` 의 사용법은 다음과 같다.:\n",
    "\n",
    "```python\n",
    "dataset = datasets.ImageFolder('path/to/data', transform=transform)\n",
    "```\n",
    "\n",
    "`'path/to/data'` 은 이미지가 있는 디렉토리이다. `transform`은 이미지를 전처리하기 위한 방법이다. [`transforms`](http://pytorch.org/docs/master/torchvision/transforms.html) module은  `torchvision` 패키지의 서브모듈로 다양한 이미지 전처리 메소드를 제공한다.  \n",
    "ImageFolder는 다음과 같은 구조로 구성되어 있어야 한다.:\n",
    "```\n",
    "root/dog/xxx.png\n",
    "root/dog/xxy.png\n",
    "root/dog/xxz.png\n",
    "\n",
    "root/cat/123.png\n",
    "root/cat/nsdf3.png\n",
    "root/cat/asd932_.png\n",
    "```\n",
    "\n",
    "각각의 클래스의 이름으로 된 디렉토리가 있어야 한다. (예를 들면 `cat`, `dog`). 각 이미지의 label은 디렉토리의 이름과 같게 된다. 제공되는 Cat_Dog_data.zip 파일은 미리 train과 test로 나뉘어 있다.\n",
    "\n",
    "### Transforms\n",
    "\n",
    "`ImageFolder`로 사진 이미지를 읽어 들일 때 , 이미지 데이터를 신경망에서 처리할 수 있도록 적절하게 전처리 해야 한다. 일단 제각각인 사진의 크기를 같은 사이즈가 되도록 해야한다.  \n",
    "- `transforms.Resize()`  \n",
    "- `transforms.CenterCrop()`\n",
    "- `transforms.RandomResizedCrop()` 등\n",
    "\n",
    "`transforms.ToTensor()`로 이미지를 반드시 PyTorch tensors 로 변환해야 한다. 여러가지 변환은  `transforms.Compose()`로 묶어서 처리가 가능하다. \n",
    "\n",
    "해당 전처리는 순서대로 수행된다.:\n",
    "\n",
    "```python\n",
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "```\n",
    "\n",
    "참고) [documentation](http://pytorch.org/docs/master/torchvision/transforms.html). \n",
    "\n",
    "### Data Loaders\n",
    "\n",
    "`ImageFolder` 는 이미지를 전처리하여 데이터 셋으로 만든다. 이렇게 만들어진 이미지 데이터 셋을 [`DataLoader`](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader)로 읽어들인다. `DataLoader`로 이미지와 이미지의 label을 읽어 들일 수 있다. shuffle하면 각 epoch 에서 데이터를 읽어 들이기 전에 이미지 데이터를 섞어준다.\n",
    "\n",
    "```python\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "```\n",
    "\n",
    "`dataloader` 는 iterator로 `next()`메소드로 for loop를 통해 반복적으로 읽어들인다.\n",
    "\n",
    "```python\n",
    "# Looping through it, get a batch on each loop \n",
    "for images, labels in dataloader:\n",
    "    pass\n",
    "\n",
    "# Get one batch\n",
    "images, labels = next(iter(dataloader))\n",
    "```\n",
    " \n",
    ">**실습 :**  `ImageFolder`로 `Cat_Dog_data/train` 폴더에서 이미지를 읽어 들여보시오. transforms을 정의하고 dataloader로 생성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "data_dir = 'Cat_Dog_data/train'\n",
    "\n",
    "transform = \n",
    "dataset = \n",
    "dataloader = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to test your data loader\n",
    "images, labels = next(iter(dataloader))\n",
    "image = images[0].numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "이미지를 임의로 회전, 반전, 스케일 변환, crop등을 통해 다양하게 변환시킨다. 이렇게 이미지를 임의로 변형해서 신경망을 훈련하면 이미지 분류의 성능을 더 향상시킬수 있다.  \n",
    "\n",
    "다음과 같이 transform을 수행할 수 있다.:\n",
    "\n",
    "```python\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5], \n",
    "                                                            [0.5, 0.5, 0.5])])\n",
    "```\n",
    "\n",
    " `transforms.Normalize`로 이미지를 normalize 할 수 있다. means 과 standard deviations을 지정한다.  \n",
    " \n",
    "```input[channel] = (input[channel] - mean[channel]) / std[channel]```\n",
    "\n",
    "Normalizing 을 하면 신경망의 학습이 더 잘 수행된다. \n",
    "\n",
    "\n",
    ">**실습 :** train data와 test data에 대해 transforms를 정의한다 (normalization 은 일단 제외)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = \n",
    "\n",
    "test_transforms = \n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to the trainloader or testloader \n",
    "data_iter = iter(testloader)\n",
    "\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
    "\n",
    "for ii in range(4):\n",
    "    ax = axes[ii]\n",
    "    image = images[ii].numpy().transpose((1,2,0))\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform된 이미지를 확인해 보자.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
