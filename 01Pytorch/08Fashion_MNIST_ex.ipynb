{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "[구글 Colab에서 실행하기](https://colab.research.google.com/github/aonekoda/DL-PyTorch/blob/master/01Basics/07Fashion_MNIST_ex.ipynb)\n",
    "\n",
    "직접 neural network를 정의하고 훈련하여 image 분류기를 만들어 보자.  \n",
    "[Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)을 사용한다. 이 데이터 셋은 28x28 크기의 greyscale images로 각종 의류에 대한 이미지 데이터 셋이다. 이 데이터 셋은 앞서 본 MNIST 보다는 좀 더 복잡한 패턴을 가지고 있다.\n",
    "\n",
    "![img](../assets/fashion-mnist-sprite.png)\n",
    "\n",
    "이 실습을 통해 각자의 neural network로 이미지 분류기를 생성한다. 앞에서 본 MNIST 분류기의 코드를 참조하여 구현할 수 있을 것이다.  \n",
    "\n",
    "일단 필요한 패키지를 import하는 것 부터 시작해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision의 datasets를 통해 FasionMNIST 데이터 셋을 다운로드하고 DataLoader로 데이터를 읽어 들인다.  \n",
    "- 총 10개의 class로 되어 있다.  \n",
    "- class : ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('data', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러들인 이미지 데이터를 화면에 출력하여 제대로 읽어 들여졌는지 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "images = images.numpy()\n",
    "\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(class_name[labels[idx].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "각자만의 모형을 구현해 보자. MNIT 이미지 분류기와 유사하게 28x28 크기로 총 784 pixels의 이미지이다. 총 10개의 class로 되어 있다.  \n",
    "class : ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
    "\n",
    "hidden layer의 갯수, hidden unit의 갯수, drop out의 사용여부, loss function, optimizer 등과 관련된 여러가지 설정은 개인의 판단에 따라 적절히 선택하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "class Classifier(nn.Module):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "먼저 loss 함수와 optimizer를 설정한다. [criterion](http://pytorch.org/docs/master/nn.html#loss-functions)은 `nn.CrossEntropyLoss` 또는 `nn.NLLLoss`로 설정할 수 있다. 또한 [optimizer](http://pytorch.org/docs/master/optim.html) 는 `optim.SGD` 또는 `optim.Adam`로 설정 가능 하다.\n",
    "\n",
    "모형을 훈련하기 위해 다음과 같은 사항을 고려한다:\n",
    "\n",
    "* forward pass를 수행한다.\n",
    "* loss를 계산한다.\n",
    "* `loss.backward()` 로 backward pass를 수행하고 gradients를 계산한다.\n",
    "* optimizer의 step으로 weights를 업데이트한다.\n",
    "\n",
    "hidden units, learning rate... 등은 hyper parameter로 각자 알맞은 값으로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the network, define the criterion and optimizer\n",
    "model = \n",
    "criterion = \n",
    "optimizer = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the network here\n",
    "epochs = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Trained Networks\n",
    "test data set으로 훈련된 모형을 평가한다. test loss와 accuracy를 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = 0\n",
    "test_loss = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for images, labels in testloader:\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    test_loss += loss.item()*images.size(0)\n",
    "    \n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "test_loss = test_loss/len(testloader.dataset)\n",
    "acc = corrects.double()/len(testloader.dataset)\n",
    "\n",
    "print(\"Test Loss : {:.4f}, Accuracy : {:.4f}\".format(test_loss, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "\n",
    "훈련된 모형에 대해 test데이터를 활용하여 이미지를 분류해 보고 결과를 시각화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "\n",
    "output = model(images)\n",
    "\n",
    "ps, preds = torch.max(output, 1)\n",
    "\n",
    "images = images.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\"{} ({})\".format(class_name[preds[idx].item()], class_name[labels[idx].item()]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
